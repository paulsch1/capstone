{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_loader import load_names_from_web, holdout_split, year_split\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, accuracy_score\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw = load_names_from_web(category='national', hide_pre_1937=True, use_existing_files=True)\n",
    "# traintestval, holdout = year_split(dfraw, holdout_size=30)\n",
    "trainval, test = year_split(dfraw, holdout_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1937,\n",
       " 1938,\n",
       " 1939,\n",
       " 1940,\n",
       " 1941,\n",
       " 1942,\n",
       " 1943,\n",
       " 1944,\n",
       " 1945,\n",
       " 1946,\n",
       " 1947,\n",
       " 1948,\n",
       " 1949,\n",
       " 1950,\n",
       " 1951,\n",
       " 1952,\n",
       " 1953,\n",
       " 1954,\n",
       " 1955,\n",
       " 1956,\n",
       " 1957,\n",
       " 1958,\n",
       " 1959,\n",
       " 1960,\n",
       " 1961,\n",
       " 1962,\n",
       " 1963,\n",
       " 1964,\n",
       " 1965,\n",
       " 1966,\n",
       " 1967,\n",
       " 1968,\n",
       " 1969,\n",
       " 1970,\n",
       " 1971,\n",
       " 1972,\n",
       " 1973,\n",
       " 1974,\n",
       " 1975,\n",
       " 1976,\n",
       " 1977,\n",
       " 1978,\n",
       " 1979,\n",
       " 1980,\n",
       " 1981,\n",
       " 1982,\n",
       " 1983,\n",
       " 1984,\n",
       " 1985,\n",
       " 1986,\n",
       " 1987,\n",
       " 1988,\n",
       " 1989,\n",
       " 1990,\n",
       " 1991,\n",
       " 1992]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(trainval['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_known_names(data):\n",
    "\n",
    "    names = data.groupby(['state', 'name', 'M/F']).size().reset_index()\n",
    "    names = names[['state', 'name', 'M/F']]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_names(data, first_year_to_predict, cutoff=10):\n",
    "    '''\n",
    "    Select names that have had at least one year at or above the cutoff count?\n",
    "    Could also try to redo this to do the cutoff for the most recent known year's data\n",
    "    '''\n",
    "\n",
    "    data_noleak = data[data['year'] < first_year_to_predict]\n",
    "    names = data_noleak[data_noleak['count'] >= cutoff][['state', 'name', 'M/F']].drop_duplicates()\n",
    "    # display(names)\n",
    "    data = names.merge(data, how='left', on=['state', 'name', 'M/F'])\n",
    "    # display(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(df):\n",
    "\n",
    "    '''\n",
    "    PEAKS\n",
    "    '''\n",
    "\n",
    "    peaks = df.loc[df.groupby(['state', 'name', 'M/F'])['count'].idxmax()][['state', 'name', 'M/F', 'year']]\n",
    "    peaks = peaks.rename(columns={'year': 'peak_year'})\n",
    "    df = df.merge(peaks, how='left', on=['state', 'name', 'M/F'])\n",
    "    # display(df)\n",
    "    df['has_peaked'] = df.apply(lambda row: 1 if row['year'] >= row['peak_year'] else 0, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>M/F</th>\n",
       "      <th>count</th>\n",
       "      <th>peak_year</th>\n",
       "      <th>has_peaked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>655103</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>M</td>\n",
       "      <td>59340</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655119</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Adam</td>\n",
       "      <td>M</td>\n",
       "      <td>23489</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643065</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Lindsey</td>\n",
       "      <td>F</td>\n",
       "      <td>8681</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643071</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>F</td>\n",
       "      <td>7491</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655159</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>M</td>\n",
       "      <td>5634</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643120</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Latoya</td>\n",
       "      <td>F</td>\n",
       "      <td>3151</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643137</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Sheena</td>\n",
       "      <td>F</td>\n",
       "      <td>2634</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643158</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Lacey</td>\n",
       "      <td>F</td>\n",
       "      <td>2383</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643169</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Joanna</td>\n",
       "      <td>F</td>\n",
       "      <td>2120</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643229</th>\n",
       "      <td>US</td>\n",
       "      <td>1983</td>\n",
       "      <td>Kate</td>\n",
       "      <td>F</td>\n",
       "      <td>1334</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  year         name M/F  count  peak_year  has_peaked\n",
       "655103    US  1983  Christopher   M  59340       1984           0\n",
       "655119    US  1983         Adam   M  23489       1984           0\n",
       "643065    US  1983      Lindsey   F   8681       1984           0\n",
       "643071    US  1983       Alicia   F   7491       1984           0\n",
       "655159    US  1983       Marcus   M   5634       1984           0\n",
       "643120    US  1983       Latoya   F   3151       1984           0\n",
       "643137    US  1983       Sheena   F   2634       1984           0\n",
       "643158    US  1983        Lacey   F   2383       1984           0\n",
       "643169    US  1983       Joanna   F   2120       1984           0\n",
       "643229    US  1983         Kate   F   1334       1984           0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = classify(trainval)\n",
    "example[(example['peak_year'] == 1984) & (example['year'] == 1983)].sort_values(by='count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictor, data_held_out, first_year_to_predict, metric='accuracy'):\n",
    "\n",
    "    # display('data_held_out:')\n",
    "    # display(data_held_out)\n",
    "\n",
    "    # most_recent_year = data_held_out['year'].max()\n",
    "    most_recent_year = first_year_to_predict - 1\n",
    "    \n",
    "    # years_to_predict = range(first_year_to_predict, most_recent_year+1)\n",
    "\n",
    "    # only allow the model to see data from before the year to predict\n",
    "    historical_data = data_held_out[data_held_out['year'] < first_year_to_predict]\n",
    "\n",
    "    # display('historical_data:')\n",
    "    # display(historical_data)\n",
    "\n",
    "    # get our model's predictions\n",
    "    predictions = predictor.predict(historical_data)\n",
    "\n",
    "    all_known_names = get_all_known_names(historical_data)\n",
    "\n",
    "    # now we need to know the \"answers\" -- what the real classes are, based on information in the \"future\"\n",
    "    data_held_out = classify(data_held_out)\n",
    "    data_held_out = data_held_out[data_held_out['year'] == most_recent_year]\n",
    "    # print(f'Predictions for {year_to_predict}:')\n",
    "\n",
    "    # names_to_predict = all_known_names.copy()\n",
    "    # names_to_predict['year'] = year_to_predict\n",
    "    # display(names_to_predict)\n",
    "\n",
    "    observed = all_known_names.merge(data_held_out, how='left', on=['state', 'name', 'M/F'])\n",
    "\n",
    "    observed['y'] = observed['has_peaked'].fillna(1) # if nothing for this name for this year, it has already peaked, so 1\n",
    "    # display(observed)\n",
    "\n",
    "    score_df = observed.merge(predictions, how='left', on=['state', 'name', 'M/F'], suffixes=('_true', '_pred'))\n",
    "    # display(score_df)\n",
    "\n",
    "    y_true = score_df['y_true']\n",
    "    y_pred = score_df['y_pred']\n",
    "\n",
    "    '''\n",
    "    if metric == 'msle':\n",
    "        loss = mean_squared_log_error(y_true, y_pred)\n",
    "        print(f'Loss: {loss}')\n",
    "\n",
    "    if metric == 'rank':\n",
    "        y_true = y_true.rank()\n",
    "        y_pred = y_pred.rank()\n",
    "        score = np.sum(np.abs(y_true-y_pred))/(len(y_true)*(len(y_true)-1))\n",
    "        print(f'Score: {score}')\n",
    "\n",
    "    if metric == 'rank_mae':\n",
    "        y_true = y_true.rank()\n",
    "        y_pred = y_pred.rank()\n",
    "        loss = mean_absolute_error(y_true, y_pred)\n",
    "        print(f'Loss: {loss}')\n",
    "\n",
    "    if metric == 'kendalltau':\n",
    "        y_true = y_true.rank()\n",
    "        y_pred = y_pred.rank()\n",
    "        tau, _ = kendalltau(y_true, y_pred)\n",
    "        print(f'Tau: {tau}')\n",
    "    '''\n",
    "\n",
    "    if metric == 'accuracy':\n",
    "        score = accuracy_score(y_true, y_pred)\n",
    "        print(f'Score: {score}')\n",
    "    \n",
    "    '''\n",
    "    top_F_true = score_df[score_df['M/F'] == 'F'][['name', 'y_true']].sort_values(by='y_true', ascending=False).reset_index(drop=True)\n",
    "    top_F_pred = score_df[score_df['M/F'] == 'F'][['name', 'y_pred']].sort_values(by='y_pred', ascending=False).reset_index(drop=True)\n",
    "    top_M_true = score_df[score_df['M/F'] == 'M'][['name', 'y_true']].sort_values(by='y_true', ascending=False).reset_index(drop=True)\n",
    "    top_M_pred = score_df[score_df['M/F'] == 'M'][['name', 'y_pred']].sort_values(by='y_pred', ascending=False).reset_index(drop=True)\n",
    "    top = pd.concat([top_F_true, top_F_pred, top_M_true, top_M_pred], axis=1, ignore_index=True)\n",
    "    '''\n",
    "    display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyClassifier():\n",
    "\n",
    "    def __init__(self, strategy='after_peak'):\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def predict(self, historical_data):\n",
    "\n",
    "        all_known_names = get_all_known_names(historical_data)\n",
    "\n",
    "        most_recent_year = historical_data['year'].max()\n",
    "\n",
    "        predictions = all_known_names.copy()\n",
    "\n",
    "        if self.strategy == 'constant':\n",
    "            predictions['y'] = 1\n",
    "        elif self.strategy == 'after_peak':\n",
    "            historical_data = classify(historical_data)\n",
    "            most_recent_year_data = historical_data[historical_data['year'] == most_recent_year].drop(columns=['year'])\n",
    "            predictions = predictions.merge(most_recent_year_data, how='left', on=['state', 'name', 'M/F'])\n",
    "            predictions['peak_year'] = predictions['peak_year'].fillna(0)\n",
    "            predictions['y'] = predictions['peak_year'].apply(lambda x: 1 if x < most_recent_year else 0)\n",
    "            # display(predictions)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8126976954360596\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>M/F</th>\n",
       "      <th>year</th>\n",
       "      <th>count_true</th>\n",
       "      <th>peak_year_true</th>\n",
       "      <th>has_peaked_true</th>\n",
       "      <th>y_true</th>\n",
       "      <th>count_pred</th>\n",
       "      <th>peak_year_pred</th>\n",
       "      <th>has_peaked_pred</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>M</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>14509.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14509.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Abbie</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Abby</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>US</td>\n",
       "      <td>Zelma</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>US</td>\n",
       "      <td>Zena</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>US</td>\n",
       "      <td>Zina</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>US</td>\n",
       "      <td>Zoe</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>US</td>\n",
       "      <td>Zoey</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4426 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state   name M/F    year  count_true  peak_year_true  has_peaked_true  \\\n",
       "0       US  Aaron   F  1992.0        91.0          1980.0              1.0   \n",
       "1       US  Aaron   M  1992.0     14509.0          1989.0              1.0   \n",
       "2       US  Abbey   F  1992.0       431.0          1999.0              0.0   \n",
       "3       US  Abbie   F  1992.0       260.0          2003.0              0.0   \n",
       "4       US   Abby   F  1992.0      1081.0          2003.0              0.0   \n",
       "...    ...    ...  ..     ...         ...             ...              ...   \n",
       "4421    US  Zelma   F  1992.0         8.0          1938.0              1.0   \n",
       "4422    US   Zena   F  1992.0        52.0          1964.0              1.0   \n",
       "4423    US   Zina   F  1992.0        21.0          1964.0              1.0   \n",
       "4424    US    Zoe   F  1992.0       982.0          2012.0              0.0   \n",
       "4425    US   Zoey   F  1992.0       145.0          2012.0              0.0   \n",
       "\n",
       "      y_true  count_pred  peak_year_pred  has_peaked_pred  y_pred  \n",
       "0        1.0        91.0          1980.0              1.0       1  \n",
       "1        1.0     14509.0          1989.0              1.0       1  \n",
       "2        0.0       431.0          1990.0              1.0       1  \n",
       "3        0.0       260.0          1990.0              1.0       1  \n",
       "4        0.0      1081.0          1983.0              1.0       1  \n",
       "...      ...         ...             ...              ...     ...  \n",
       "4421     1.0         8.0          1938.0              1.0       1  \n",
       "4422     1.0        52.0          1964.0              1.0       1  \n",
       "4423     1.0        21.0          1964.0              1.0       1  \n",
       "4424     0.0       982.0          1992.0              1.0       0  \n",
       "4425     0.0       145.0          1992.0              1.0       0  \n",
       "\n",
       "[4426 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_year_to_predict = 1993\n",
    "cutoff = 100\n",
    "# data_to_fit = select_top_names(trainval, first_year_to_predict=first_year_to_predict, cutoff=0)\n",
    "data_to_eval = select_top_names(test, first_year_to_predict=first_year_to_predict, cutoff=cutoff)\n",
    "evaluate(predictor=DummyClassifier(strategy='after_peak'), data_held_out=data_to_eval, first_year_to_predict=first_year_to_predict, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "\n",
    "class MyPredictor():\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # params\n",
    "        # cols_to_keep = ['this_year', 'M/F', 'sum', 'median_age', 'thisyear_count', 'diff',] # best overall?\n",
    "        # cols_to_keep = ['this_year', 'M/F', 'sum', 'median_age', 'thisyear_count', 'diff', 'first_letter_1_pct', 'first_letter_2_pct', 'first_letter_3_pct'] # first letter pct change helps in some years\n",
    "        # cols_to_keep = ['this_year', 'M/F', 'sum', 'median_age', 'thisyear_count', 'diff', 'thisyear_count_opp']\n",
    "        cols_to_keep = ['M/F', 'sum', 'median_age', 'thisyear_count', 'diff', 'thisyear_count_opp', 'diff2', 'shift', 'pct_change', 'accel', 'after_peak', 'years_since_peak', 'first_letter_1_pct', 'first_letter_2_pct', 'first_letter_3_pct']\n",
    "        categorical_features = ['M/F', 'after_peak']\n",
    "        max_leaf_nodes = 31 # 16\n",
    "        max_iter = 100 # 100\n",
    "        loss = 'log_loss' # abs better than default\n",
    "\n",
    "        categorical_features = [True if f in categorical_features else False for f in cols_to_keep]\n",
    "        # print(categorical_features)\n",
    "        \n",
    "        self.pipe = make_pipeline(\n",
    "            ColumnTransformer(\n",
    "                transformers=[\n",
    "                    # ('category_encoder', LabelEncoder(), categorical_features),\n",
    "                    ('cols_to_keep', 'passthrough', cols_to_keep),\n",
    "                ], remainder='drop'),\n",
    "            HistGradientBoostingClassifier(\n",
    "                random_state=0,\n",
    "                categorical_features=categorical_features,\n",
    "                max_leaf_nodes=max_leaf_nodes,\n",
    "                max_iter=max_iter,\n",
    "                loss=loss\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.gender_encoding = {'M': 0, 'F': 1}\n",
    "\n",
    "    def preprocess(self, df, latest_known_year):\n",
    "\n",
    "        # print(f'Latest known year: {latest_known_year}')\n",
    "\n",
    "        # find median age of people with name, \n",
    "        # total born with that name,\n",
    "        # and latest year's count\n",
    "\n",
    "        df = df.copy()\n",
    "\n",
    "        df = classify(df)\n",
    "        df['after_peak'] = df['peak_year'].apply(lambda x: 1 if x < latest_known_year else 0)\n",
    "\n",
    "        df = df.sort_values(by='year')\n",
    "        df['cumsum'] = df.groupby(['state', 'name', 'M/F'])['count'].cumsum()\n",
    "        df['sum'] = df.groupby(['state', 'name', 'M/F'])['count'].transform('sum')\n",
    "\n",
    "        df['diff'] = df.groupby(['state', 'name', 'M/F'])['count'].diff()\n",
    "        df['diff2'] = df.groupby(['state', 'name', 'M/F'])['count'].diff(2)\n",
    "        df['shift'] = df.groupby(['state', 'name', 'M/F'])['count'].shift()\n",
    "        df['pct_change'] = df.groupby(['state', 'name', 'M/F'])['count'].pct_change()\n",
    "        df['accel'] = df.groupby(['state', 'name', 'M/F'])['diff'].diff()\n",
    "\n",
    "        percentage_of_total_per_year = {}\n",
    "        percentage_change_per_year = {}\n",
    "\n",
    "        def first_letters(df, n, percentage_of_total_per_year, percentage_change_per_year):\n",
    "            df['first_letter_'+str(n)] = df['name'].str[0:n].str.lower()\n",
    "            total_names_per_year = df.groupby(['year', 'state', 'M/F'])['count'].sum()\n",
    "            letter_names_per_year = df.groupby(['year', 'state', 'M/F', 'first_letter_'+str(n)])['count'].sum()\n",
    "            percentage_of_total_per_year[n] = (letter_names_per_year / total_names_per_year).rename('first_letter_'+str(n)+'_pct')\n",
    "            # display(percentage_of_total_per_year)\n",
    "            percentage_change_per_year[n] = percentage_of_total_per_year[n].groupby(['state', 'M/F', 'first_letter_'+str(n)]).pct_change().rename('first_letter_'+str(n)+'_pct_change')\n",
    "            # display(percentage_change_per_year)\n",
    "            return df\n",
    "        \n",
    "        for n in range(1, 4):\n",
    "            df = first_letters(df, n, percentage_of_total_per_year, percentage_change_per_year)\n",
    "        \n",
    "        # display(df[(df['name'] == 'Maximus')])\n",
    "\n",
    "        medians = df[df['cumsum'] >= df['sum']/2]\n",
    "        medians = medians.drop_duplicates(subset=['state', 'name', 'M/F'], keep='first')\n",
    "        medians['median_age'] = latest_known_year - medians['year']\n",
    "        # display(medians[medians['name'] == 'Madison'])\n",
    "\n",
    "        medians = medians.drop(['count', 'cumsum', 'diff', 'shift', 'pct_change', 'accel', 'diff2', 'after_peak'], axis=1)\n",
    "\n",
    "        thisyear = df[df['year'] == latest_known_year][['state', 'name', 'M/F', 'count', 'diff', 'shift', 'pct_change', 'accel', 'diff2', 'after_peak']].rename(columns={'count': 'thisyear_count'})\n",
    "        # thisyear = thisyear.merge(percentage_of_total_per_year, how='left', on=['year', 'state', 'M/F', 'first_letter_1'])\n",
    "        # thisyear = thisyear.merge(percentage_change_per_year, how='left', on=['year', 'state', 'M/F', 'first_letter_1'])\n",
    "        # thisyear = thisyear.rename(columns={'year': 'this_year'})\n",
    "\n",
    "        sex_counts = thisyear.groupby(['state', 'name', 'M/F'])['thisyear_count'].sum()\n",
    "        thisyear_swapped = thisyear.copy()\n",
    "        thisyear_swapped['M/F'] = thisyear_swapped['M/F'].replace({'M': 'F', 'F': 'M'})\n",
    "        thisyear_swapped = thisyear_swapped.merge(sex_counts, how='left', on=['state', 'name', 'M/F'], suffixes=('', '_opp'))\n",
    "        thisyear_swapped['M/F'] = thisyear_swapped['M/F'].replace({'M': 'F', 'F': 'M'})\n",
    "        thisyear_swapped['thisyear_count_opp'] = thisyear_swapped['thisyear_count_opp'].fillna(0)\n",
    "        thisyear = thisyear_swapped\n",
    "        # display(thisyear)\n",
    "\n",
    "        df = medians.merge(thisyear, how='left', on=['state', 'name', 'M/F']).rename(columns={'year': 'median_year'})\n",
    "        # df2[['thisyear_count']] = df2[['thisyear_count']].fillna(0) # might want to shift this to 2 and fill in 2s for missing years? or maybe not\n",
    "\n",
    "        # this is sort of a rough assumption that if a row didn't exist for this year, not only is the count 0, but so is the diff, shift and pct_change. not always true if the prior year had a count, but often true\n",
    "        df[['thisyear_count', 'diff', 'shift', 'pct_change', 'accel', 'diff2']] = df[['thisyear_count', 'diff', 'shift', 'pct_change', 'accel', 'diff2']].fillna(0)\n",
    "\n",
    "        df['after_peak'] = df['after_peak'].fillna(1)\n",
    "        df['years_since_peak'] = latest_known_year - df['peak_year']\n",
    "\n",
    "        df['year'] = latest_known_year\n",
    "\n",
    "        for n in range(1, 4):\n",
    "            df = df.merge(percentage_of_total_per_year[n], how='left', on=['year', 'state', 'M/F', 'first_letter_'+str(n)])\n",
    "            df = df.merge(percentage_change_per_year[n], how='left', on=['year', 'state', 'M/F', 'first_letter_'+str(n)])\n",
    "            df['first_letter_'+str(n)+'_pct'] = df['first_letter_'+str(n)+'_pct'].fillna(0)\n",
    "            df['first_letter_'+str(n)+'_pct_change'] = df['first_letter_'+str(n)+'_pct_change'].fillna(0)\n",
    "\n",
    "        # display(df2)\n",
    "        # display(df2.groupby(['state','name','M/F']).ngroups)\n",
    "\n",
    "        # change M/F to 0/1 so it works with various models\n",
    "        # (even HistGradientBoostingRegressor, which accepts categorical values,\n",
    "        # still needs those values to be numbers not strings)\n",
    "        df['M/F'] = df['M/F'].map(self.gender_encoding)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, historical_data, first_year_to_predict, years_to_fit=1, weight_decay=0.99):\n",
    "        # first, we do need to find our y\n",
    "        historical_data = classify(historical_data)\n",
    "        \n",
    "        # first things first, we don't want to know about future data\n",
    "        historical_data = historical_data[historical_data['year'] < first_year_to_predict]\n",
    "        # at this point the data we don't want to know should be inaccessible\n",
    "\n",
    "        # maybe there is a better way to do the following\n",
    "        # but basically we just want the original columns for X and one new labeled column for y\n",
    "        X_orig = historical_data[['state', 'year', 'name', 'M/F', 'count']]\n",
    "        y_orig = historical_data[['state', 'year', 'name', 'M/F', 'has_peaked']]\n",
    "        y_orig = y_orig.rename(columns={'has_peaked': 'y'})\n",
    "        y_orig['M/F'] = y_orig['M/F'].map(self.gender_encoding)\n",
    "\n",
    "        X_all = pd.DataFrame()\n",
    "        y_all = pd.Series()\n",
    "\n",
    "        # each year_to_fit is the year that's essentially our y for that loop\n",
    "        for year_to_fit in range(first_year_to_predict - years_to_fit, first_year_to_predict):\n",
    "\n",
    "            # now we \"know\" even less for X\n",
    "            X = X_orig[X_orig['year'] <= year_to_fit]\n",
    "            # y = historical_data[historical_data['year'] == year_to_fit]\n",
    "\n",
    "            X = self.preprocess(X, latest_known_year=year_to_fit)\n",
    "            # y = y[['state', 'name', 'M/F', 'count']].rename(columns={'count': 'y'})\n",
    "\n",
    "            # display(X)\n",
    "\n",
    "            data = X.merge(y_orig, how='left', on=['state', 'year', 'name', 'M/F'])\n",
    "            data['y'] = data['y'].fillna(1) # if nothing for this name for this year, it has already peaked, so 1\n",
    "\n",
    "            # assert data['y'].isna().any() == False\n",
    "\n",
    "            # display(data)\n",
    "\n",
    "            X = data.drop(columns=['y'])\n",
    "            y = data['y']\n",
    "            X['sample_weight'] = weight_decay ** (first_year_to_predict - year_to_fit)\n",
    "\n",
    "            X_all = pd.concat([X_all, X], ignore_index=True)\n",
    "            y_all = pd.concat([y_all, y], ignore_index=True)\n",
    "        \n",
    "        temp = X_all.copy()\n",
    "        temp['y'] = y_all\n",
    "        display(temp)\n",
    "        display(temp.columns)\n",
    "\n",
    "        sample_weights = X_all['sample_weight']\n",
    "        X_all = X_all.drop(columns=['sample_weight'])\n",
    "\n",
    "        self.pipe.fit(X_all, y_all, **{'histgradientboostingclassifier__sample_weight': sample_weights})\n",
    "        # this seems like a silly way to pass params to individual steps of the pipeline, but it's true. See: https://stackoverflow.com/questions/36205850/sklearn-pipeline-applying-sample-weights-after-applying-a-polynomial-feature-t\n",
    "\n",
    "    def predict(self, historical_data):\n",
    "\n",
    "        # all_known_names = get_all_known_names(historical_data)\n",
    "\n",
    "        # predictions = []\n",
    "\n",
    "        # display('historical_data in predict:')\n",
    "        # display(historical_data)\n",
    "        # display('years_to_predict:')\n",
    "        # display(years_to_predict)\n",
    "\n",
    "        most_recent_year = historical_data['year'].max()\n",
    "\n",
    "        # predictions = all_known_names.copy()\n",
    "\n",
    "        # most_recent_year_data = historical_data[historical_data['year'] == most_recent_year]\n",
    "        # predictions = predictions.merge(most_recent_year_data, how='left', on=['state', 'name', 'M/F'])\n",
    "        # display(predictions)\n",
    "\n",
    "        # display('historical_data in predict loop:')\n",
    "        # display(historical_data)\n",
    "\n",
    "        df = self.preprocess(historical_data, latest_known_year=most_recent_year)\n",
    "        # df = self.preprocess(historical_data, years_to_predict[0] - 1)\n",
    "\n",
    "        df = df[df['year'] == most_recent_year]\n",
    "\n",
    "        df['y'] = self.pipe.predict(df)\n",
    "\n",
    "        # df['year'] = year_to_predict\n",
    "        # display(df)\n",
    "\n",
    "        # if we want to simply, do the following; \n",
    "        # but for now, might be useful to see all data displayed.\n",
    "        # df = df[['state', 'year', 'name', 'M/F', 'y']]\n",
    "\n",
    "        predictions = df.copy()\n",
    "\n",
    "        '''\n",
    "        assumed_new_year_of_historical_data = df[['state', 'year', 'name', 'M/F', 'y']].rename(columns={'y': 'count'})\n",
    "        assumed_new_year_of_historical_data['M/F'] = assumed_new_year_of_historical_data['M/F'].map({v: k for k, v in self.gender_encoding.items()})\n",
    "        historical_data = pd.concat([historical_data, assumed_new_year_of_historical_data], ignore_index=True)\n",
    "        '''\n",
    "\n",
    "        # predictions = pd.concat(predictions, ignore_index=True)\n",
    "\n",
    "        # we have to reverse the mapping to send our predictions\n",
    "        # (at least the way we currently have it set up)\n",
    "        predictions['M/F'] = predictions['M/F'].map({v: k for k, v in self.gender_encoding.items()})\n",
    "\n",
    "        # predictions.loc[predictions['y'] < 4.5, 'y'] = 2\n",
    "\n",
    "        display(predictions)\n",
    "        # display(predictions[predictions['y'] < 4.5])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>median_year</th>\n",
       "      <th>name</th>\n",
       "      <th>M/F</th>\n",
       "      <th>peak_year</th>\n",
       "      <th>has_peaked</th>\n",
       "      <th>sum</th>\n",
       "      <th>first_letter_1</th>\n",
       "      <th>first_letter_2</th>\n",
       "      <th>first_letter_3</th>\n",
       "      <th>...</th>\n",
       "      <th>years_since_peak</th>\n",
       "      <th>year</th>\n",
       "      <th>first_letter_1_pct</th>\n",
       "      <th>first_letter_1_pct_change</th>\n",
       "      <th>first_letter_2_pct</th>\n",
       "      <th>first_letter_2_pct_change</th>\n",
       "      <th>first_letter_3_pct</th>\n",
       "      <th>first_letter_3_pct_change</th>\n",
       "      <th>sample_weight</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>1937</td>\n",
       "      <td>Jerimiah</td>\n",
       "      <td>0</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>j</td>\n",
       "      <td>je</td>\n",
       "      <td>jer</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.168296</td>\n",
       "      <td>-0.021434</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>-0.016231</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>1937</td>\n",
       "      <td>Adonis</td>\n",
       "      <td>0</td>\n",
       "      <td>1946</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>a</td>\n",
       "      <td>ad</td>\n",
       "      <td>ado</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.035509</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.257483</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>1937</td>\n",
       "      <td>Gage</td>\n",
       "      <td>0</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>g</td>\n",
       "      <td>ga</td>\n",
       "      <td>gag</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.055321</td>\n",
       "      <td>-0.015659</td>\n",
       "      <td>0.018627</td>\n",
       "      <td>-0.010274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>1937</td>\n",
       "      <td>Nikolas</td>\n",
       "      <td>0</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>ni</td>\n",
       "      <td>nik</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>-0.017184</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>-0.014660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>1937</td>\n",
       "      <td>Claribel</td>\n",
       "      <td>1</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>c</td>\n",
       "      <td>cl</td>\n",
       "      <td>cla</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1948</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>-0.040156</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>-0.036637</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112033</th>\n",
       "      <td>US</td>\n",
       "      <td>1977</td>\n",
       "      <td>Destinee</td>\n",
       "      <td>1</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>d</td>\n",
       "      <td>de</td>\n",
       "      <td>des</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>-0.070074</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>-0.057271</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.159930</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112034</th>\n",
       "      <td>US</td>\n",
       "      <td>1977</td>\n",
       "      <td>Najee</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>n</td>\n",
       "      <td>na</td>\n",
       "      <td>naj</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.016569</td>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.087693</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112035</th>\n",
       "      <td>US</td>\n",
       "      <td>1977</td>\n",
       "      <td>Itzel</td>\n",
       "      <td>1</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>i</td>\n",
       "      <td>it</td>\n",
       "      <td>itz</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>-0.062262</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112036</th>\n",
       "      <td>US</td>\n",
       "      <td>1977</td>\n",
       "      <td>Breeanna</td>\n",
       "      <td>1</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>b</td>\n",
       "      <td>br</td>\n",
       "      <td>bre</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.028791</td>\n",
       "      <td>-0.005786</td>\n",
       "      <td>0.014976</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>-0.106124</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112037</th>\n",
       "      <td>US</td>\n",
       "      <td>1977</td>\n",
       "      <td>Pooja</td>\n",
       "      <td>1</td>\n",
       "      <td>1977</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>p</td>\n",
       "      <td>po</td>\n",
       "      <td>poo</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.012190</td>\n",
       "      <td>-0.084447</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.306539</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.796491</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112038 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  median_year      name  M/F  peak_year  has_peaked  sum  \\\n",
       "0         US         1937  Jerimiah    0       1937           1    5   \n",
       "1         US         1937    Adonis    0       1946           0   10   \n",
       "2         US         1937      Gage    0       1942           0   10   \n",
       "3         US         1937   Nikolas    0       1937           1    6   \n",
       "4         US         1937  Claribel    1       1937           1   18   \n",
       "...      ...          ...       ...  ...        ...         ...  ...   \n",
       "112033    US         1977  Destinee    1       1977           1   39   \n",
       "112034    US         1977     Najee    0       1977           1    5   \n",
       "112035    US         1977     Itzel    1       1977           1    5   \n",
       "112036    US         1977  Breeanna    1       1977           1   12   \n",
       "112037    US         1977     Pooja    1       1977           1   23   \n",
       "\n",
       "       first_letter_1 first_letter_2 first_letter_3  ...  years_since_peak  \\\n",
       "0                   j             je            jer  ...                11   \n",
       "1                   a             ad            ado  ...                 2   \n",
       "2                   g             ga            gag  ...                 6   \n",
       "3                   n             ni            nik  ...                11   \n",
       "4                   c             cl            cla  ...                11   \n",
       "...               ...            ...            ...  ...               ...   \n",
       "112033              d             de            des  ...                 0   \n",
       "112034              n             na            naj  ...                 0   \n",
       "112035              i             it            itz  ...                 0   \n",
       "112036              b             br            bre  ...                 0   \n",
       "112037              p             po            poo  ...                 0   \n",
       "\n",
       "        year  first_letter_1_pct  first_letter_1_pct_change  \\\n",
       "0       1948            0.168296                  -0.021434   \n",
       "1       1948            0.035509                   0.007770   \n",
       "2       1948            0.055321                  -0.015659   \n",
       "3       1948            0.007727                  -0.017184   \n",
       "4       1948            0.094005                   0.012204   \n",
       "...      ...                 ...                        ...   \n",
       "112033  1977            0.038961                  -0.070074   \n",
       "112034  1977            0.016569                   0.169047   \n",
       "112035  1977            0.003076                  -0.062262   \n",
       "112036  1977            0.028791                  -0.005786   \n",
       "112037  1977            0.012190                  -0.084447   \n",
       "\n",
       "        first_letter_2_pct  first_letter_2_pct_change  first_letter_3_pct  \\\n",
       "0                 0.019686                  -0.016231            0.012099   \n",
       "1                 0.000517                   0.022720            0.000133   \n",
       "2                 0.018627                  -0.010274            0.000000   \n",
       "3                 0.001596                  -0.014660            0.000000   \n",
       "4                 0.004255                  -0.040156            0.004063   \n",
       "...                    ...                        ...                 ...   \n",
       "112033            0.012544                  -0.057271            0.000947   \n",
       "112034            0.008202                   0.087693            0.000003   \n",
       "112035            0.000004                   0.000000            0.000004   \n",
       "112036            0.014976                   0.020864            0.002782   \n",
       "112037            0.000243                   0.306539            0.000011   \n",
       "\n",
       "        first_letter_3_pct_change  sample_weight    y  \n",
       "0                       -0.057831         0.7397  1.0  \n",
       "1                        0.257483         0.7397  1.0  \n",
       "2                        0.000000         0.7397  1.0  \n",
       "3                        0.000000         0.7397  1.0  \n",
       "4                       -0.036637         0.7397  1.0  \n",
       "...                           ...            ...  ...  \n",
       "112033                   0.159930         0.9900  0.0  \n",
       "112034                   0.000000         0.9900  0.0  \n",
       "112035                   0.000000         0.9900  0.0  \n",
       "112036                  -0.106124         0.9900  0.0  \n",
       "112037                   0.796491         0.9900  0.0  \n",
       "\n",
       "[112038 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['state', 'median_year', 'name', 'M/F', 'peak_year', 'has_peaked', 'sum',\n",
       "       'first_letter_1', 'first_letter_2', 'first_letter_3', 'median_age',\n",
       "       'thisyear_count', 'diff', 'shift', 'pct_change', 'accel', 'diff2',\n",
       "       'after_peak', 'thisyear_count_opp', 'years_since_peak', 'year',\n",
       "       'first_letter_1_pct', 'first_letter_1_pct_change', 'first_letter_2_pct',\n",
       "       'first_letter_2_pct_change', 'first_letter_3_pct',\n",
       "       'first_letter_3_pct_change', 'sample_weight', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>M/F</th>\n",
       "      <th>median_year</th>\n",
       "      <th>peak_year</th>\n",
       "      <th>has_peaked</th>\n",
       "      <th>sum</th>\n",
       "      <th>first_letter_1</th>\n",
       "      <th>first_letter_2</th>\n",
       "      <th>first_letter_3</th>\n",
       "      <th>...</th>\n",
       "      <th>thisyear_count_opp</th>\n",
       "      <th>years_since_peak</th>\n",
       "      <th>year</th>\n",
       "      <th>first_letter_1_pct</th>\n",
       "      <th>first_letter_1_pct_change</th>\n",
       "      <th>first_letter_2_pct</th>\n",
       "      <th>first_letter_2_pct_change</th>\n",
       "      <th>first_letter_3_pct</th>\n",
       "      <th>first_letter_3_pct_change</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>Shelva</td>\n",
       "      <td>F</td>\n",
       "      <td>1940</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>1028</td>\n",
       "      <td>s</td>\n",
       "      <td>sh</td>\n",
       "      <td>she</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.092766</td>\n",
       "      <td>-0.007713</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.022871</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Shelba</td>\n",
       "      <td>F</td>\n",
       "      <td>1941</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>1964</td>\n",
       "      <td>s</td>\n",
       "      <td>sh</td>\n",
       "      <td>she</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.092766</td>\n",
       "      <td>-0.007713</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.022871</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Melvyn</td>\n",
       "      <td>M</td>\n",
       "      <td>1942</td>\n",
       "      <td>1938</td>\n",
       "      <td>1</td>\n",
       "      <td>3013</td>\n",
       "      <td>m</td>\n",
       "      <td>me</td>\n",
       "      <td>mel</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.083813</td>\n",
       "      <td>-0.049057</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>-0.049408</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>-0.053206</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Dick</td>\n",
       "      <td>M</td>\n",
       "      <td>1944</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>14058</td>\n",
       "      <td>d</td>\n",
       "      <td>di</td>\n",
       "      <td>dic</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>0.064203</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.360184</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.595606</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Myrtle</td>\n",
       "      <td>F</td>\n",
       "      <td>1944</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>15448</td>\n",
       "      <td>m</td>\n",
       "      <td>my</td>\n",
       "      <td>myr</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.096376</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>-0.043273</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>-0.026740</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>US</td>\n",
       "      <td>Jaylen</td>\n",
       "      <td>M</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>j</td>\n",
       "      <td>ja</td>\n",
       "      <td>jay</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.179265</td>\n",
       "      <td>-0.043854</td>\n",
       "      <td>0.049668</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.015905</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>US</td>\n",
       "      <td>Payton</td>\n",
       "      <td>F</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>p</td>\n",
       "      <td>pa</td>\n",
       "      <td>pay</td>\n",
       "      <td>...</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.011322</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.061277</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>5.955524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>US</td>\n",
       "      <td>Connor</td>\n",
       "      <td>F</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>236</td>\n",
       "      <td>c</td>\n",
       "      <td>co</td>\n",
       "      <td>con</td>\n",
       "      <td>...</td>\n",
       "      <td>4607.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.090971</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>-0.024929</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>US</td>\n",
       "      <td>Bronte</td>\n",
       "      <td>F</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>b</td>\n",
       "      <td>br</td>\n",
       "      <td>bro</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.055148</td>\n",
       "      <td>-0.014464</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.110663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>US</td>\n",
       "      <td>Alexus</td>\n",
       "      <td>F</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>707</td>\n",
       "      <td>a</td>\n",
       "      <td>al</td>\n",
       "      <td>ale</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.143005</td>\n",
       "      <td>-0.033572</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.039140</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.106434</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4426 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state    name M/F  median_year  peak_year  has_peaked    sum  \\\n",
       "0       US  Shelva   F         1940       1937           1   1028   \n",
       "1       US  Shelba   F         1941       1937           1   1964   \n",
       "2       US  Melvyn   M         1942       1938           1   3013   \n",
       "3       US    Dick   M         1944       1937           1  14058   \n",
       "4       US  Myrtle   F         1944       1937           1  15448   \n",
       "...    ...     ...  ..          ...        ...         ...    ...   \n",
       "4421    US  Jaylen   M         1992       1992           1    109   \n",
       "4422    US  Payton   F         1992       1992           1    560   \n",
       "4423    US  Connor   F         1992       1992           1    236   \n",
       "4424    US  Bronte   F         1992       1992           1    185   \n",
       "4425    US  Alexus   F         1992       1992           1    707   \n",
       "\n",
       "     first_letter_1 first_letter_2 first_letter_3  ...  thisyear_count_opp  \\\n",
       "0                 s             sh            she  ...                 NaN   \n",
       "1                 s             sh            she  ...                 NaN   \n",
       "2                 m             me            mel  ...                 0.0   \n",
       "3                 d             di            dic  ...                 0.0   \n",
       "4                 m             my            myr  ...                 0.0   \n",
       "...             ...            ...            ...  ...                 ...   \n",
       "4421              j             ja            jay  ...                 0.0   \n",
       "4422              p             pa            pay  ...               262.0   \n",
       "4423              c             co            con  ...              4607.0   \n",
       "4424              b             br            bro  ...                 0.0   \n",
       "4425              a             al            ale  ...                 0.0   \n",
       "\n",
       "      years_since_peak  year  first_letter_1_pct  first_letter_1_pct_change  \\\n",
       "0                   55  1992            0.092766                  -0.007713   \n",
       "1                   55  1992            0.092766                  -0.007713   \n",
       "2                   54  1992            0.083813                  -0.049057   \n",
       "3                   55  1992            0.091003                   0.064203   \n",
       "4                   55  1992            0.096376                   0.013237   \n",
       "...                ...   ...                 ...                        ...   \n",
       "4421                 0  1992            0.179265                  -0.043854   \n",
       "4422                 0  1992            0.011322                   0.055696   \n",
       "4423                 0  1992            0.090971                   0.013571   \n",
       "4424                 0  1992            0.055148                  -0.014464   \n",
       "4425                 0  1992            0.143005                  -0.033572   \n",
       "\n",
       "      first_letter_2_pct  first_letter_2_pct_change  first_letter_3_pct  \\\n",
       "0               0.021895                   0.022871            0.008309   \n",
       "1               0.021895                   0.022871            0.008309   \n",
       "2               0.000596                  -0.049408            0.000450   \n",
       "3               0.004170                   0.360184            0.000006   \n",
       "4               0.000490                  -0.043273            0.000403   \n",
       "...                  ...                        ...                 ...   \n",
       "4421            0.049668                   0.003470            0.001045   \n",
       "4422            0.007973                   0.061277            0.000185   \n",
       "4423            0.012252                  -0.024929            0.000624   \n",
       "4424            0.044932                  -0.012426            0.004079   \n",
       "4425            0.041068                   0.039140            0.018525   \n",
       "\n",
       "      first_letter_3_pct_change    y  \n",
       "0                     -0.057600  1.0  \n",
       "1                     -0.057600  1.0  \n",
       "2                     -0.053206  1.0  \n",
       "3                      0.595606  1.0  \n",
       "4                     -0.026740  1.0  \n",
       "...                         ...  ...  \n",
       "4421                   0.015905  0.0  \n",
       "4422                   5.955524  0.0  \n",
       "4423                   0.003406  0.0  \n",
       "4424                   0.110663  0.0  \n",
       "4425                   0.106434  0.0  \n",
       "\n",
       "[4426 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8436511522819702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>M/F</th>\n",
       "      <th>year_true</th>\n",
       "      <th>count</th>\n",
       "      <th>peak_year_true</th>\n",
       "      <th>has_peaked_true</th>\n",
       "      <th>y_true</th>\n",
       "      <th>median_year</th>\n",
       "      <th>peak_year_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>thisyear_count_opp</th>\n",
       "      <th>years_since_peak</th>\n",
       "      <th>year_pred</th>\n",
       "      <th>first_letter_1_pct</th>\n",
       "      <th>first_letter_1_pct_change</th>\n",
       "      <th>first_letter_2_pct</th>\n",
       "      <th>first_letter_2_pct_change</th>\n",
       "      <th>first_letter_3_pct</th>\n",
       "      <th>first_letter_3_pct_change</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>...</td>\n",
       "      <td>14509.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.143005</td>\n",
       "      <td>-0.033572</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.087438</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.087438</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>M</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>14509.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>1989</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.091399</td>\n",
       "      <td>0.036444</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.034494</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.034494</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>1990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.143005</td>\n",
       "      <td>-0.033572</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.025855</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>-0.046038</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Abbie</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>1990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.143005</td>\n",
       "      <td>-0.033572</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.025855</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>-0.046038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Abby</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1983</td>\n",
       "      <td>1983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.143005</td>\n",
       "      <td>-0.033572</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.025855</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>-0.046038</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>US</td>\n",
       "      <td>Zelma</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1948</td>\n",
       "      <td>1938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.039121</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>US</td>\n",
       "      <td>Zena</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>1964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.085496</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>US</td>\n",
       "      <td>Zina</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1964</td>\n",
       "      <td>1964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.259300</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.259300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>US</td>\n",
       "      <td>Zoe</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>1992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.409261</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.409261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>US</td>\n",
       "      <td>Zoey</td>\n",
       "      <td>F</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991</td>\n",
       "      <td>1992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.409261</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.409261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4426 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state   name M/F  year_true    count  peak_year_true  has_peaked_true  \\\n",
       "0       US  Aaron   F     1992.0     91.0          1980.0              1.0   \n",
       "1       US  Aaron   M     1992.0  14509.0          1989.0              1.0   \n",
       "2       US  Abbey   F     1992.0    431.0          1999.0              0.0   \n",
       "3       US  Abbie   F     1992.0    260.0          2003.0              0.0   \n",
       "4       US   Abby   F     1992.0   1081.0          2003.0              0.0   \n",
       "...    ...    ...  ..        ...      ...             ...              ...   \n",
       "4421    US  Zelma   F     1992.0      8.0          1938.0              1.0   \n",
       "4422    US   Zena   F     1992.0     52.0          1964.0              1.0   \n",
       "4423    US   Zina   F     1992.0     21.0          1964.0              1.0   \n",
       "4424    US    Zoe   F     1992.0    982.0          2012.0              0.0   \n",
       "4425    US   Zoey   F     1992.0    145.0          2012.0              0.0   \n",
       "\n",
       "      y_true  median_year  peak_year_pred  ...  thisyear_count_opp  \\\n",
       "0        1.0         1980            1980  ...             14509.0   \n",
       "1        1.0         1981            1989  ...                91.0   \n",
       "2        0.0         1985            1990  ...                 0.0   \n",
       "3        0.0         1979            1990  ...                 0.0   \n",
       "4        0.0         1983            1983  ...                 0.0   \n",
       "...      ...          ...             ...  ...                 ...   \n",
       "4421     1.0         1948            1938  ...                 0.0   \n",
       "4422     1.0         1965            1964  ...                 0.0   \n",
       "4423     1.0         1964            1964  ...                 0.0   \n",
       "4424     0.0         1981            1992  ...                 0.0   \n",
       "4425     0.0         1991            1992  ...                 0.0   \n",
       "\n",
       "      years_since_peak year_pred first_letter_1_pct first_letter_1_pct_change  \\\n",
       "0                   12      1992           0.143005                 -0.033572   \n",
       "1                    3      1992           0.091399                  0.036444   \n",
       "2                    2      1992           0.143005                 -0.033572   \n",
       "3                    2      1992           0.143005                 -0.033572   \n",
       "4                    9      1992           0.143005                 -0.033572   \n",
       "...                ...       ...                ...                       ...   \n",
       "4421                54      1992           0.000862                  0.337240   \n",
       "4422                28      1992           0.000862                  0.337240   \n",
       "4423                28      1992           0.000862                  0.337240   \n",
       "4424                 0      1992           0.000862                  0.337240   \n",
       "4425                 0      1992           0.000862                  0.337240   \n",
       "\n",
       "      first_letter_2_pct  first_letter_2_pct_change  first_letter_3_pct  \\\n",
       "0               0.000055                  -0.087438            0.000055   \n",
       "1               0.007758                   0.034494            0.007758   \n",
       "2               0.003535                   0.025855            0.001072   \n",
       "3               0.003535                   0.025855            0.001072   \n",
       "4               0.003535                   0.025855            0.001072   \n",
       "...                  ...                        ...                 ...   \n",
       "4421            0.000050                   0.035345            0.000019   \n",
       "4422            0.000050                   0.035345            0.000031   \n",
       "4423            0.000013                  -0.259300            0.000013   \n",
       "4424            0.000682                   0.409261            0.000682   \n",
       "4425            0.000682                   0.409261            0.000682   \n",
       "\n",
       "      first_letter_3_pct_change  y_pred  \n",
       "0                     -0.087438     0.0  \n",
       "1                      0.034494     1.0  \n",
       "2                     -0.046038     1.0  \n",
       "3                     -0.046038     0.0  \n",
       "4                     -0.046038     1.0  \n",
       "...                         ...     ...  \n",
       "4421                  -0.039121     1.0  \n",
       "4422                   0.085496     1.0  \n",
       "4423                  -0.259300     1.0  \n",
       "4424                   0.409261     0.0  \n",
       "4425                   0.409261     0.0  \n",
       "\n",
       "[4426 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_year_to_predict = 1993\n",
    "years_to_predict_in_fitting = 15\n",
    "years_to_fit_in_fitting = 30\n",
    "name_usage_cutoff = 100\n",
    "my_predictor = MyPredictor()\n",
    "data_to_fit = select_top_names(trainval, first_year_to_predict=first_year_to_predict, cutoff=name_usage_cutoff)\n",
    "data_to_eval = select_top_names(test, first_year_to_predict=first_year_to_predict, cutoff=name_usage_cutoff)\n",
    "my_predictor.fit(historical_data=data_to_fit, first_year_to_predict=first_year_to_predict-years_to_predict_in_fitting, years_to_fit=years_to_fit_in_fitting)\n",
    "evaluate(predictor=my_predictor, data_held_out=data_to_eval, first_year_to_predict=first_year_to_predict, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
