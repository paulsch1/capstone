{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_loader import load_names_from_web, holdout_split\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw = load_names_from_web(category='national', hide_pre_1937=True, use_existing_files=True)\n",
    "traintestval, holdout = holdout_split(dfraw)\n",
    "trainval, test = holdout_split(traintestval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>M/F</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>2000</td>\n",
       "      <td>Emily</td>\n",
       "      <td>F</td>\n",
       "      <td>25957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>2000</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>F</td>\n",
       "      <td>23085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>2000</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>F</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>2000</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>F</td>\n",
       "      <td>17712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>2000</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>F</td>\n",
       "      <td>17631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866154</th>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>Zygmunt</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866155</th>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>Zyheem</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866156</th>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>Zyking</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866157</th>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>Zyn</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866158</th>\n",
       "      <td>US</td>\n",
       "      <td>2019</td>\n",
       "      <td>Zyran</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866159 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       state  year     name M/F  count\n",
       "0         US  2000    Emily   F  25957\n",
       "1         US  2000   Hannah   F  23085\n",
       "2         US  2000   Ashley   F  17998\n",
       "3         US  2000    Sarah   F  17712\n",
       "4         US  2000   Alexis   F  17631\n",
       "...      ...   ...      ...  ..    ...\n",
       "866154    US  2019  Zygmunt   M      5\n",
       "866155    US  2019   Zyheem   M      5\n",
       "866156    US  2019   Zyking   M      5\n",
       "866157    US  2019      Zyn   M      5\n",
       "866158    US  2019    Zyran   M      5\n",
       "\n",
       "[866159 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_known_names(data):\n",
    "\n",
    "    names = data.groupby(['state', 'name', 'M/F']).size().reset_index()\n",
    "    names = names[['state', 'name', 'M/F']]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for 1993:\n",
      "Loss: 0.2048210376167501\n",
      "Predictions for 1994:\n",
      "Loss: 0.23748961163833746\n",
      "Predictions for 1995:\n",
      "Loss: 0.2944425991076037\n",
      "Predictions for 1996:\n",
      "Loss: 0.345131451965153\n",
      "Predictions for 1997:\n",
      "Loss: 0.39172905985529827\n",
      "Predictions for 1998:\n",
      "Loss: 0.46885007263667744\n",
      "Predictions for 1999:\n",
      "Loss: 0.5491453016551922\n",
      "Predictions for 2000:\n",
      "Loss: 0.6217554907260967\n",
      "Predictions for 2001:\n",
      "Loss: 0.6990891031726914\n",
      "Predictions for 2002:\n",
      "Loss: 0.7676513819895272\n",
      "Predictions for 2003:\n",
      "Loss: 0.8523447530601621\n",
      "Predictions for 2004:\n",
      "Loss: 0.924022538364825\n",
      "Predictions for 2005:\n",
      "Loss: 0.9822846196943936\n",
      "Predictions for 2006:\n",
      "Loss: 1.091002004905991\n",
      "Predictions for 2007:\n",
      "Loss: 1.1744378337438273\n",
      "Predictions for 2008:\n",
      "Loss: 1.2724181760639353\n",
      "Predictions for 2009:\n",
      "Loss: 1.3272445805372455\n",
      "Predictions for 2010:\n",
      "Loss: 1.3913044503027057\n",
      "Predictions for 2011:\n",
      "Loss: 1.4703149252733005\n",
      "Predictions for 2012:\n",
      "Loss: 1.5317617595476543\n",
      "Predictions for 2013:\n",
      "Loss: 1.5798350289998204\n",
      "Predictions for 2014:\n",
      "Loss: 1.6906521612870573\n",
      "Predictions for 2015:\n",
      "Loss: 1.762586027393145\n",
      "Predictions for 2016:\n",
      "Loss: 1.818275511339159\n",
      "Predictions for 2017:\n",
      "Loss: 1.896902187167079\n",
      "Predictions for 2018:\n",
      "Loss: 1.948923492368697\n",
      "Predictions for 2019:\n",
      "Loss: 2.0214582948026387\n",
      "Predictions for 2020:\n",
      "Loss: 2.077420638109086\n",
      "Predictions for 2021:\n",
      "Loss: 2.1637281623284985\n",
      "Predictions for 2022:\n",
      "Loss: 2.2347171567357904\n"
     ]
    }
   ],
   "source": [
    "def evaluate(predictor, data_held_out, first_year_to_predict, metric='msle'):\n",
    "\n",
    "    most_recent_year = data_held_out['year'].max()\n",
    "    \n",
    "    years_to_predict = range(first_year_to_predict, most_recent_year+1)\n",
    "\n",
    "    # only allow the model to see data from before the year to predict\n",
    "    historical_data = data_held_out[data_held_out['year'] < first_year_to_predict]\n",
    "\n",
    "    # get our model's predictions\n",
    "    predictions = predictor.predict(historical_data, years_to_predict)\n",
    "\n",
    "    all_known_names = get_all_known_names(historical_data)\n",
    "\n",
    "    for year_to_predict in years_to_predict:\n",
    "\n",
    "        print(f'Predictions for {year_to_predict}:')\n",
    "\n",
    "        names_to_predict = all_known_names.copy()\n",
    "        names_to_predict['year'] = year_to_predict\n",
    "        # display(names_to_predict)\n",
    "\n",
    "        observed = names_to_predict.merge(data_held_out, how='left', on=['state', 'name', 'M/F', 'year'])\n",
    "\n",
    "        # for now, fill in missing values with 2, same as FiveThirtyEight did;\n",
    "        # reasoning: missing values could be 0 to 4, so average is 2\n",
    "        observed['count'] = observed['count'].fillna(2)\n",
    "        # observed = observed.rename(columns={'count': 'count_true'})\n",
    "        # display(observed)\n",
    "\n",
    "        score_df = observed.merge(predictions, how='left', on=['state', 'name', 'M/F', 'year'], suffixes=('_true', '_pred'))\n",
    "        # display(score_df)\n",
    "\n",
    "        y_true = score_df['count_true']\n",
    "        y_pred = score_df['count_pred']\n",
    "\n",
    "        if metric == 'msle':\n",
    "            loss = mean_squared_log_error(y_true, y_pred)\n",
    "            print(f'Loss: {loss}')\n",
    "\n",
    "evaluate(DummyPredictor(strategy='naive'), test, 1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyPredictor():\n",
    "\n",
    "    def __init__(self, strategy='naive'):\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def predict(self, historical_data, years_to_predict):\n",
    "\n",
    "        all_known_names = get_all_known_names(historical_data)\n",
    "\n",
    "        predictions = []\n",
    "        previous_year_data = historical_data[historical_data['year'] == years_to_predict[0] - 1].drop(columns=['year'])\n",
    "\n",
    "        for year_to_predict in years_to_predict:\n",
    "\n",
    "            prediction = all_known_names.copy()\n",
    "            prediction['year'] = year_to_predict\n",
    "\n",
    "            if self.strategy == 'naive':\n",
    "                prediction = prediction.merge(previous_year_data, how='left', on=['state', 'name', 'M/F'])\n",
    "                prediction['count'] = prediction['count'].fillna(2)\n",
    "                # display(prediction)\n",
    "            elif self.strategy == 'mean':\n",
    "                prediction['count'] = previous_year_data['count'].mean()\n",
    "                # display(prediction)\n",
    "\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        predictions = pd.concat(predictions, ignore_index=True)\n",
    "        # display(predictions)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
